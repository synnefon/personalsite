const toShavian = require("to-shavian");

// Shavian shorthand words (single character representations)
const SHAVIAN_SHORTHAND = {
  "ð‘ž": "the",
  "ð‘": "of",
  "ð‘¯": "and",
  "ð‘‘": "to",
};

// Shavian to ARPABET mapping
const SHAVIAN_TO_ARPABET = {
  // Shavian-Only Punctuation
  "Â·": "",

  // Consonants
  "ð‘": "P",
  "ð‘š": "B",
  "ð‘‘": "T",
  "ð‘›": "D",
  "ð‘’": "K",
  "ð‘œ": "G",
  "ð‘“": "F",
  "ð‘": "V",
  "ð‘”": "TH",
  "ð‘ž": "DH",
  "ð‘•": "S",
  "ð‘Ÿ": "Z",
  "ð‘–": "SH",
  "ð‘ ": "ZH",
  "ð‘—": "CH",
  "ð‘¡": "JH",
  "ð‘£": "HH",
  "ð‘¢": "W",
  "ð‘˜": "Y",
  "ð‘®": "R",
  "ð‘¤": "L",
  "ð‘¥": "M",
  "ð‘¯": "N",
  "ð‘™": "NG",

  // Vowels
  "ð‘°": "IY", // eat
  "ð‘¦": "IH", // if
  "ð‘±": "EY", // age
  "ð‘§": "EH", // egg
  "ð‘¨": "AE", // ash
  "ð‘­": "AA", // ah
  "ð‘·": "AO", // awe
  "ð‘´": "OW", // oak
  "ð‘«": "UH", // wool
  "ð‘µ": "UW", // ooze
  "ð‘³": "AH", // up
  "ð‘©": "AX", // schwa
  "ð‘²": "AY", // ice
  "ð‘¬": "AW", // out
  "ð‘¶": "OY", // oil

  // Rhotic Vowels (compound)
  "ð‘»": "ER", // err
  "ð‘¸": "AA+R", // are
  "ð‘¹": "AO+R", // or
  "ð‘º": "EH+R", // air
  "ð‘½": "IH+R", // ear
  "ð‘¼": "AX+R", // schwa + r
  "ð‘¾": "IY+AX", // IY + schwa
  "ð‘¿": "Y+UW", // Y + UW
};

export const shavianateParagraphs = (paragraphs) => {
  return paragraphs
    .split("\n")
    .map((sentence) => toShavian(sentence))
    .join("\n");
};

export const getArpabetFromShavian = (word) => {
  // Strip punctuation from the word to check if it's shorthand
  const cleanWord = word.replace(/[^\u{10450}-\u{1047F}]/gu, "");

  // Map each character to ARPABET
  const characters = [...cleanWord];
  const arpabet = characters.map((c) => SHAVIAN_TO_ARPABET[c] ?? c).join(" ");

  // Check if it's a single-character shorthand word and add that info
  if (characters.length === 1 && SHAVIAN_SHORTHAND[cleanWord]) {
    return `${arpabet} (${SHAVIAN_SHORTHAND[cleanWord]})`;
  }

  return arpabet;
};

// Process line parts into tokens
const tokenizeLine = (line, tokens) => {
  line.split(/(\s+)/).forEach((part) => {
    if (!part) return;

    if (/^\s+$/.test(part)) {
      tokens.push({
        type: "whitespace",
        english: part,
        shavian: part,
        index: null,
      });
      return;
    }

    const match = part.match(/^([^\w]*)(\w+)([^\w]*)$/);
    if (!match) {
      // Pure punctuation - no word part
      tokens.push({
        type: "punctuation",
        english: part,
        shavian: toShavian(part),
        index: null,
      });
      return;
    }

    const [, leadPunct, word, trailPunct] = match;
    if (leadPunct)
      tokens.push({
        type: "punctuation",
        english: leadPunct,
        shavian: toShavian(leadPunct),
        index: null,
      });

    const wordIndex = tokens.filter((t) => t.type === "word").length;
    tokens.push({
      type: "word",
      english: word,
      shavian: toShavian(word),
      index: wordIndex,
    });

    if (trailPunct)
      tokens.push({
        type: "punctuation",
        english: trailPunct,
        shavian: toShavian(trailPunct),
        index: null,
      });
  });
};

// Parse text into tokens with word mappings
export const tokenizeText = (text) => {
  const tokens = [];
  const lines = text.split("\n");

  for (let lineIndex = 0; lineIndex < lines.length; lineIndex++) {
    const line = lines[lineIndex];

    if (lineIndex > 0) {
      tokens.push({
        type: "newline",
        english: "\n",
        shavian: "\n",
        index: null,
      });
    }

    tokenizeLine(line, tokens);
  }

  return tokens;
};
