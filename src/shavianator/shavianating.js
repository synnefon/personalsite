// Token types enum
export const TokenType = {
  WORD: "word",
  PUNCTUATION: "punctuation",
  WHITESPACE: "whitespace",
  NEWLINE: "newline",
};

// Global reference to toShavian function, set externally
let toShavian = null;

export const setToShavian = (fn) => {
  toShavian = fn;
};

// Shavian shorthand words (single character representations)
const SHAVIAN_SHORTHAND = {
  "ð‘ž": "the",
  "ð‘": "of",
  "ð‘¯": "and",
  "ð‘‘": "to",
  "ð‘©": "a",
};

// Shavian to ARPABET mapping
const SHAVIAN_TO_ARPABET = {
  // Shavian-Only Punctuation
  "Â·": "",

  // Consonants
  "ð‘": "P",
  "ð‘š": "B",
  "ð‘‘": "T",
  "ð‘›": "D",
  "ð‘’": "K",
  "ð‘œ": "G",
  "ð‘“": "F",
  "ð‘": "V",
  "ð‘”": "TH",
  "ð‘ž": "DH",
  "ð‘•": "S",
  "ð‘Ÿ": "Z",
  "ð‘–": "SH",
  "ð‘ ": "ZH",
  "ð‘—": "CH",
  "ð‘¡": "JH",
  "ð‘£": "HH",
  "ð‘¢": "W",
  "ð‘˜": "Y",
  "ð‘®": "R",
  "ð‘¤": "L",
  "ð‘¥": "M",
  "ð‘¯": "N",
  "ð‘™": "NG",

  // Vowels
  "ð‘°": "IY", // eat
  "ð‘¦": "IH", // if
  "ð‘±": "EY", // age
  "ð‘§": "EH", // egg
  "ð‘¨": "AE", // ash
  "ð‘­": "AA", // ah
  "ð‘·": "AO", // awe
  "ð‘´": "OW", // oak
  "ð‘«": "UH", // wool
  "ð‘µ": "UW", // ooze
  "ð‘³": "AH", // up
  "ð‘©": "AX", // schwa
  "ð‘²": "AY", // ice
  "ð‘¬": "AW", // out
  "ð‘¶": "OY", // oil

  // Rhotic Vowels (compound)
  "ð‘»": "ER", // err
  "ð‘¸": "AA+R", // are
  "ð‘¹": "AO+R", // or
  "ð‘º": "EH+R", // air
  "ð‘½": "IH+R", // ear
  "ð‘¼": "AX+R", // schwa + r
  "ð‘¾": "IY+AX", // IY + schwa
  "ð‘¿": "Y+UW", // Y + UW
};

const ARPABET_TO_SHAVIAN = Object.fromEntries(
  Object.entries(SHAVIAN_TO_ARPABET).map(([shavian, arpabet]) => [
    arpabet,
    shavian,
  ])
);

export const shavianateParagraphs = (paragraphs) =>
  paragraphs.split("\n").map(toShavian).join("\n");

export const getArpabetFromShavian = (word) => {
  const clean = word.replace(/[^\u{10450}-\u{1047F}]/gu, "");
  const chars = [...clean];
  const arpabet = chars.map((c) => SHAVIAN_TO_ARPABET[c] ?? c).join(" ");
  return chars.length === 1 && SHAVIAN_SHORTHAND[clean]
    ? `${arpabet} (${SHAVIAN_SHORTHAND[clean]})`
    : arpabet;
};

// Convert quotes to guillemets - keep other punctuation as-is
const convertQuotesToGuillemets = (text, quoteState) =>
  text.replace(/["\u201C\u201D]/g, () => {
    const g = quoteState.isOpen ? "Â«" : "Â»";
    quoteState.isOpen = !quoteState.isOpen;
    return g;
  });

const makeWhitespaceToken = (str) => ({
  type: TokenType.WHITESPACE,
  english: str,
  shavian: str,
  index: null,
});

const makePunctuationToken = (str, quoteState) => ({
  type: TokenType.PUNCTUATION,
  english: str,
  shavian: convertQuotesToGuillemets(str, quoteState),
  index: null,
});

const makeWordToken = (word, wordCount) => ({
  type: TokenType.WORD,
  english: word,
  shavian:
    word.toLowerCase() === "a" ? ARPABET_TO_SHAVIAN["AX"] : toShavian(word),
  index: wordCount,
});

// Helper: Tokenize a single segment, either whitespace, punctuation, or word (with pre/post)
function tokenizeSegment(part, quoteState, wordCountRef) {
  const tokens = [];
  if (/^\s+$/.test(part)) {
    tokens.push(makeWhitespaceToken(part));
    return tokens;
  }
  const match = part.match(/^([^\w]*)(\w[\w'\u2019'-]*\w|\w)?([^\w]*)$/);
  if (!match || !match[2]) {
    tokens.push(makePunctuationToken(part, quoteState));
    return tokens;
  }
  const [, pre, word, post] = match;
  if (pre) tokens.push(makePunctuationToken(pre, quoteState));
  tokens.push(makeWordToken(word, wordCountRef.value++));
  if (post) tokens.push(makePunctuationToken(post, quoteState));
  return tokens;
}

// Tokenize a single line into a flat array of tokens.
const tokenizeLine = (line, quoteState, existingWordCount = 0) => {
  const tokens = [];
  let wordCountRef = { value: existingWordCount };
  // split including whitespace as separate tokens
  for (const part of line.split(/(\s+)/)) {
    if (!part) continue;
    const segTokens = tokenizeSegment(part, quoteState, wordCountRef);
    tokens.push(...segTokens);
  }
  return { tokens, wordCount: wordCountRef.value };
};

export const tokenizeText = (text) => {
  const lines = text.split("\n");
  const quoteState = { isOpen: true };
  let tokens = [];
  let wordCount = 0;
  lines.forEach((line, i) => {
    if (i > 0) {
      tokens.push({
        type: TokenType.NEWLINE,
        english: "\n",
        shavian: "\n",
        index: null,
      });
    }
    const result = tokenizeLine(line, quoteState, wordCount);
    tokens = tokens.concat(result.tokens);
    wordCount = result.wordCount;
  });
  return tokens;
};
